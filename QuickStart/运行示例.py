#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DIGIMON GraphRAG è¿è¡Œç¤ºä¾‹
è¿™ä¸ªè„šæœ¬å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨DIGIMONæ¡†æ¶è¿›è¡ŒGraphRAGæŸ¥è¯¢
"""

import asyncio
import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from Core.GraphRAG import GraphRAG
from Option.Config2 import Config


def create_sample_config():
    """åˆ›å»ºç¤ºä¾‹é…ç½®"""
    config_dict = {
        # åŸºç¡€LLMé…ç½®
        'llm': {
            'api_type': 'openai',  # æˆ– 'open_llm' ç”¨äºæœ¬åœ°æ¨¡å‹
            'base_url': 'https://api.openai.com/v1',
            'model': 'gpt-3.5-turbo',
            'api_key': 'your-api-key-here'  # è¯·æ›¿æ¢ä¸ºä½ çš„API Key
        },
        
        # åµŒå…¥æ¨¡å‹é…ç½®
        'embedding': {
            'api_type': 'openai',
            'model': 'text-embedding-ada-002',
            'api_key': 'your-api-key-here',  # è¯·æ›¿æ¢ä¸ºä½ çš„API Key
            'dimensions': 1536,
            'max_token_size': 8192
        },
        
        # æ•°æ®å’Œå·¥ä½œç›®å½•
        'data_root': './Data',
        'working_dir': './',
        'exp_name': 'demo_experiment',
        
        # å›¾é…ç½®
        'graph': {
            'graph_type': 'tree_graph',
            'force': False,
            'num_layers': 3,
            'top_k': 5,
            'threshold': 0.15
        },
        
        # æ£€ç´¢é…ç½®
        'retriever': {
            'top_k': 8,
            'query_type': 'basic'
        },
        
        # æŸ¥è¯¢é…ç½®
        'query': {
            'query_type': 'qa',
            'retrieve_top_k': 15,
            'tree_search': True,
            'response_type': 'Multiple Paragraphs'
        },
        
        # åˆ†å—é…ç½®
        'chunk': {
            'chunk_token_size': 800,
            'chunk_overlap_token_size': 100,
            'chunk_method': 'chunking_by_token_size'
        }
    }
    
    return config_dict


async def demo_query_single():
    """æ¼”ç¤ºå•ä¸ªæŸ¥è¯¢"""
    print("ğŸš€ å¼€å§‹å•ä¸ªæŸ¥è¯¢æ¼”ç¤º...")
    
    # åˆ›å»ºé…ç½®
    config_dict = create_sample_config()
    config = Config(config_dict)
    
    # åˆå§‹åŒ–GraphRAGç³»ç»Ÿ
    digimon = GraphRAG(config)
    
    # ç¤ºä¾‹æŸ¥è¯¢
    query = "ä»€ä¹ˆæ˜¯GraphRAGï¼Ÿå®ƒæœ‰ä»€ä¹ˆä¼˜åŠ¿ï¼Ÿ"
    
    print(f"ğŸ“ æŸ¥è¯¢é—®é¢˜: {query}")
    print("ğŸ”„ æ­£åœ¨å¤„ç†æŸ¥è¯¢...")
    
    try:
        # æ‰§è¡ŒæŸ¥è¯¢
        result = await digimon.query(query)
        
        print("\nâœ… æŸ¥è¯¢ç»“æœ:")
        print("-" * 50)
        print(result)
        print("-" * 50)
        
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢å¤±è´¥: {str(e)}")
        print("ğŸ’¡ è¯·æ£€æŸ¥APIé…ç½®å’Œç½‘ç»œè¿æ¥")


async def demo_query_batch():
    """æ¼”ç¤ºæ‰¹é‡æŸ¥è¯¢"""
    print("\nğŸš€ å¼€å§‹æ‰¹é‡æŸ¥è¯¢æ¼”ç¤º...")
    
    # åˆ›å»ºé…ç½®
    config_dict = create_sample_config()
    config = Config(config_dict)
    
    # åˆå§‹åŒ–GraphRAGç³»ç»Ÿ
    digimon = GraphRAG(config)
    
    # ç¤ºä¾‹æŸ¥è¯¢åˆ—è¡¨
    queries = [
        "GraphRAGçš„æ ¸å¿ƒç»„ä»¶æœ‰å“ªäº›ï¼Ÿ",
        "å¦‚ä½•é€‰æ‹©åˆé€‚çš„å›¾ç±»å‹ï¼Ÿ",
        "RAPTORå’ŒLightRAGæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ"
    ]
    
    results = []
    
    for i, query in enumerate(queries, 1):
        print(f"\nğŸ“ æŸ¥è¯¢ {i}: {query}")
        print("ğŸ”„ æ­£åœ¨å¤„ç†...")
        
        try:
            result = await digimon.query(query)
            results.append({
                'query': query,
                'result': result,
                'status': 'success'
            })
            print(f"âœ… æŸ¥è¯¢ {i} å®Œæˆ")
            
        except Exception as e:
            results.append({
                'query': query,
                'result': str(e),
                'status': 'failed'
            })
            print(f"âŒ æŸ¥è¯¢ {i} å¤±è´¥: {str(e)}")
    
    # æ˜¾ç¤ºç»“æœæ‘˜è¦
    print("\nğŸ“Š æ‰¹é‡æŸ¥è¯¢ç»“æœæ‘˜è¦:")
    print("=" * 60)
    
    for i, result in enumerate(results, 1):
        status_icon = "âœ…" if result['status'] == 'success' else "âŒ"
        print(f"{status_icon} æŸ¥è¯¢ {i}: {result['query'][:30]}...")
        if result['status'] == 'success':
            print(f"   ç»“æœé•¿åº¦: {len(result['result'])} å­—ç¬¦")
        else:
            print(f"   é”™è¯¯: {result['result']}")
        print()


def check_configuration():
    """æ£€æŸ¥é…ç½®æ˜¯å¦æ­£ç¡®"""
    print("ğŸ” æ£€æŸ¥é…ç½®...")
    
    config_dict = create_sample_config()
    
    # æ£€æŸ¥API Key
    if 'your-api-key-here' in str(config_dict):
        print("âš ï¸  è­¦å‘Š: è¯·åœ¨é…ç½®ä¸­è®¾ç½®æ­£ç¡®çš„API Key")
        print("   è¯·ç¼–è¾‘ create_sample_config() å‡½æ•°ä¸­çš„ api_key å­—æ®µ")
        return False
    
    # æ£€æŸ¥æ•°æ®ç›®å½•
    data_dir = Path(config_dict['data_root'])
    if not data_dir.exists():
        print(f"âš ï¸  è­¦å‘Š: æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        print("   è¯·ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨å¹¶åŒ…å«ç›¸å…³æ–‡æ¡£")
        return False
    
    print("âœ… é…ç½®æ£€æŸ¥é€šè¿‡")
    return True


def show_usage():
    """æ˜¾ç¤ºä½¿ç”¨è¯´æ˜"""
    print("ğŸ“– DIGIMON GraphRAG ä½¿ç”¨è¯´æ˜")
    print("=" * 50)
    print()
    print("ğŸ”§ é…ç½®æ­¥éª¤:")
    print("1. è®¾ç½®API Key (OpenAIæˆ–å…¶ä»–LLMæœåŠ¡)")
    print("2. å‡†å¤‡æ•°æ®é›† (æ”¾åœ¨Dataç›®å½•ä¸‹)")
    print("3. é€‰æ‹©åˆé€‚çš„æ–¹æ³•é…ç½®æ–‡ä»¶")
    print()
    print("ğŸš€ è¿è¡Œæ–¹å¼:")
    print("1. ç›´æ¥è¿è¡Œæ­¤è„šæœ¬: python è¿è¡Œç¤ºä¾‹.py")
    print("2. ä½¿ç”¨å‘½ä»¤è¡Œ: python main.py -opt Option/Method/RAPTOR.yaml -dataset_name your_data")
    print()
    print("ğŸ“ æ”¯æŒçš„å›¾ç±»å‹:")
    print("- tree_graph: æ ‘å½¢å›¾ (RAPTOR)")
    print("- er_graph: å®ä½“å…³ç³»å›¾")
    print("- rkg_graph: ä¸°å¯ŒçŸ¥è¯†å›¾ (LightRAG)")
    print("- passage_graph: æ®µè½å›¾")
    print()
    print("ğŸ¯ æŸ¥è¯¢ç±»å‹:")
    print("- qa: é—®ç­”")
    print("- summarization: æ‘˜è¦ç”Ÿæˆ")
    print()


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ‰ æ¬¢è¿ä½¿ç”¨ DIGIMON GraphRAG æ¡†æ¶!")
    print("=" * 60)
    
    # æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
    show_usage()
    
    # æ£€æŸ¥é…ç½®
    if not check_configuration():
        print("\nâŒ é…ç½®æ£€æŸ¥å¤±è´¥ï¼Œè¯·ä¿®æ­£é…ç½®åé‡è¯•")
        return
    
    # è¯¢é—®ç”¨æˆ·é€‰æ‹©
    print("\nè¯·é€‰æ‹©è¿è¡Œæ¨¡å¼:")
    print("1. å•ä¸ªæŸ¥è¯¢æ¼”ç¤º")
    print("2. æ‰¹é‡æŸ¥è¯¢æ¼”ç¤º")
    print("3. ä»…æ˜¾ç¤ºé…ç½®ä¿¡æ¯")
    
    try:
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-3): ").strip()
        
        if choice == '1':
            await demo_query_single()
        elif choice == '2':
            await demo_query_batch()
        elif choice == '3':
            config_dict = create_sample_config()
            print("\nğŸ“‹ å½“å‰é…ç½®:")
            for key, value in config_dict.items():
                print(f"  {key}: {value}")
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")
            
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
    except Exception as e:
        print(f"\nâŒ è¿è¡Œå‡ºé”™: {str(e)}")
    
    print("\nğŸ‰ æ¼”ç¤ºç»“æŸï¼Œæ„Ÿè°¢ä½¿ç”¨!")


if __name__ == "__main__":
    # è¿è¡Œå¼‚æ­¥ä¸»å‡½æ•°
    asyncio.run(main())