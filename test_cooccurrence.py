#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€å•çš„æµ‹è¯•è„šæœ¬æ¥éªŒè¯tokenå…±ç°å…³ç³»è·Ÿè¸ªåŠŸèƒ½
"""
import json
import tempfile
from pathlib import Path
import subprocess
import pickle


def create_test_data():
    """åˆ›å»ºæµ‹è¯•æ•°æ®"""
    test_texts = [
        "Hello world, this is a test.",
        "Machine learning is amazing technology.",
        "Python programming language is powerful.",
        "Natural language processing with transformers.",
        "Deep learning models need training data."
    ]
    
    temp_dir = Path(tempfile.mkdtemp())
    test_file = temp_dir / "test_data.jsonl"
    
    with open(test_file, 'w', encoding='utf-8') as f:
        for text in test_texts:
            json.dump({"content": text}, f, ensure_ascii=False)
            f.write('\n')
    
    return temp_dir


def test_cooccurrence_tracker():
    """æµ‹è¯•å…±ç°å…³ç³»è·Ÿè¸ªå™¨"""
    print("=== Testing Token Cooccurrence Tracker ===\n")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    data_dir = create_test_data()
    print(f"Created test data in: {data_dir}")
    
    # è¿è¡Œå…±ç°å…³ç³»è·Ÿè¸ªå™¨
    output_file = Path("test_cooccurrence.pkl")
    cmd = [
        "python3", "token_cooccurrence_tracker.py",
        "--data-dir", str(data_dir),
        "--context-length", "32",  # è¾ƒå°çš„context lengthç”¨äºæµ‹è¯•
        "--batch-size", "16",
        "--num-proc", "1",  # å•è¿›ç¨‹é¿å…å¤æ‚æ€§
        "--out-file", str(output_file)
    ]
    
    print("Running cooccurrence tracker...")
    print(" ".join(cmd))
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        print("STDOUT:", result.stdout)
        if result.stderr:
            print("STDERR:", result.stderr)
        
        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
        if output_file.exists():
            print(f"\nâœ“ Output file created: {output_file}")
            
            # åŠ è½½å¹¶æ£€æŸ¥æ•°æ®
            with open(output_file, 'rb') as f:
                cooccurrence_data = pickle.load(f)
            
            print(f"âœ“ Loaded cooccurrence data with {len(cooccurrence_data)} tokens")
            
            # æ˜¾ç¤ºä¸€äº›ç»Ÿè®¡ä¿¡æ¯
            total_relationships = sum(len(cooc_set) for cooc_set in cooccurrence_data.values())
            avg_cooccurrences = total_relationships / len(cooccurrence_data) if cooccurrence_data else 0
            
            print(f"  - Total unique tokens: {len(cooccurrence_data)}")
            print(f"  - Total relationships: {total_relationships}")
            print(f"  - Average cooccurrences per token: {avg_cooccurrences:.2f}")
            
            # æ˜¾ç¤ºå‰å‡ ä¸ªtokençš„å…±ç°å…³ç³»
            print("\n  Sample cooccurrence relationships:")
            for i, (token_id, cooc_set) in enumerate(list(cooccurrence_data.items())[:3]):
                print(f"    Token {token_id}: co-occurs with {len(cooc_set)} tokens")
                print(f"      Co-occurring token IDs: {list(cooc_set)[:5]}...")  # æ˜¾ç¤ºå‰5ä¸ª
            
            return True
        else:
            print("âœ— Output file not created")
            return False
            
    except subprocess.CalledProcessError as e:
        print(f"âœ— Command failed with exit code {e.returncode}")
        print("STDOUT:", e.stdout)
        print("STDERR:", e.stderr)
        return False
    except Exception as e:
        print(f"âœ— Error: {e}")
        return False


def test_analyzer():
    """æµ‹è¯•åˆ†æå™¨"""
    print("\n=== Testing Cooccurrence Analyzer ===\n")
    
    output_file = Path("test_cooccurrence.pkl")
    if not output_file.exists():
        print("âœ— No cooccurrence data file found. Run tracker test first.")
        return False
    
    # æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯
    cmd = ["python3", "cooccurrence_analyzer.py", "--data", str(output_file), "--stats"]
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        print("âœ“ Statistics command succeeded:")
        print(result.stdout)
        
        # æµ‹è¯•æŸ¥è¯¢åŠŸèƒ½ï¼ˆå°è¯•æŸ¥è¯¢ä¸€ä¸ªå¸¸è§çš„tokenï¼‰
        cmd = ["python3", "cooccurrence_analyzer.py", "--data", str(output_file), 
               "--top-connected", "5"]
        
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        print("âœ“ Top connected tokens command succeeded:")
        print(result.stdout)
        
        return True
        
    except subprocess.CalledProcessError as e:
        print(f"âœ— Analyzer command failed with exit code {e.returncode}")
        print("STDOUT:", e.stdout)
        print("STDERR:", e.stderr)
        return False
    except Exception as e:
        print(f"âœ— Error: {e}")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("Starting token cooccurrence system tests...\n")
    
    success = True
    
    # æµ‹è¯•è·Ÿè¸ªå™¨
    if test_cooccurrence_tracker():
        print("âœ“ Cooccurrence tracker test PASSED")
    else:
        print("âœ— Cooccurrence tracker test FAILED")
        success = False
    
    # æµ‹è¯•åˆ†æå™¨
    if test_analyzer():
        print("âœ“ Cooccurrence analyzer test PASSED")
    else:
        print("âœ— Cooccurrence analyzer test FAILED")
        success = False
    
    # æ¸…ç†æµ‹è¯•æ–‡ä»¶
    test_file = Path("test_cooccurrence.pkl")
    if test_file.exists():
        test_file.unlink()
        print(f"\nCleaned up test file: {test_file}")
    
    print(f"\n{'='*50}")
    if success:
        print("ğŸ‰ ALL TESTS PASSED!")
        print("\nYour token cooccurrence tracking system is working correctly.")
        print("You can now use it with your own data by following the examples in:")
        print("  - README_token_cooccurrence.md")
        print("  - example_usage_cooccurrence.py")
    else:
        print("âŒ SOME TESTS FAILED!")
        print("Please check the error messages above.")


if __name__ == "__main__":
    main()